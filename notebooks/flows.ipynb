{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d908916-8c95-40f3-8730-22fdaf5493a6",
   "metadata": {},
   "source": [
    "# Normalizing flows\n",
    "Here is some of our work for examining how normalizing flows adapt to differently-shaped priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52bfda1-abfd-49bc-8141-7835c00fa1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import FrEIA.modules as Fm\n",
    "import FrEIA.framework as Ff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "764d3bd7-fdc3-4729-8204-52f30f35432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b495bcd3-b38b-46d9-b705-d603de0e8f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_dist = torch.distributions.MultivariateNormal(torch.zeros([1], device=device), torch.eye(1, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cafa11c-dda5-4f8f-8ebd-9f5f5bdd641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_sample(n=1000):\n",
    "    ret = torch.zeros([n,2])\n",
    "    ret[:,0] = true_dist.rsample([n]).squeeze()\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8a34b73d-67c6-4ea8-afb4-0cec3df999fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_gaussian_density(pts, alpha=0.2):\n",
    "    probs = 1.5*true_dist.log_prob(pts[:,0].unsqueeze(1)).exp()\n",
    "    for k, norm in enumerate(pts[:,1]):\n",
    "        if norm.abs() >= alpha:\n",
    "            probs[k]=0.\n",
    "        else:\n",
    "            probs[k]*= np.exp(1/alpha**2)*(-1/(alpha**2 - norm.pow(2))).exp()\n",
    "    return probs\n",
    "\n",
    "def smoothed_circle_density(pts, alpha=0.2):\n",
    "    probs = torch.zeros_like(pts[:,0])\n",
    "    norms = pts.norm(dim=1)\n",
    "    for k, norm in enumerate(norms):\n",
    "        if (1-norm).abs() < alpha:\n",
    "            probs[k] = np.exp(1/alpha**2)*(-1/(alpha**2 - (1-norm).pow(2))).exp()\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e60601e3-ed23-4afd-acc1-c53086b2f52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5241e-01, 1.3278e-04, 0.0000e+00], device='cuda:2')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([[0.4,0],[0.4,0.1],[0.4,0.3]], device=device)\n",
    "smoothed_density(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "215c7fe5-e3e9-445b-b024-aa56672d28a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pts = 200\n",
    "ret = np.zeros([num_pts, num_pts])\n",
    "pts = []\n",
    "for i, a in enumerate(np.linspace(-3, 3, num_pts)):\n",
    "    for j, b in enumerate(np.linspace(-3, 3, num_pts)):\n",
    "        pts.append(torch.tensor([a,b], device=device, dtype=torch.float))\n",
    "pts = torch.stack(pts)\n",
    "arr = smoothed_density(pts).reshape(num_pts, num_pts).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f169b005-6e22-4261-98ab-0de4917972d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edbb1da76334918a94174ef66d6b4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "sns.heatmap(arr.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7dc67d42-4a1a-4713-8489-d5f77575ec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(mod, num_pts=170):\n",
    "    xsize, ysize = num_pts, num_pts\n",
    "    batch, idxs = [],[]\n",
    "    outs = []\n",
    "    for i, a in enumerate(np.linspace(-2, 2, xsize)):\n",
    "        for j, b in enumerate(np.linspace(-0.4,0.4, ysize)):\n",
    "            batch.append(torch.tensor([a,b], dtype=torch.float, device=device))\n",
    "            idxs.append((i,j))\n",
    "            if len(batch) > 200:\n",
    "                batch = torch.stack(batch)\n",
    "                vals, logDs = mod(batch)\n",
    "                outs.append((vals.detach(), logDs.detach()))\n",
    "                batch, idxs = [], []\n",
    "    if len(batch) > 0:\n",
    "        batch = torch.stack(batch)\n",
    "        vals, logDs = mod(batch)\n",
    "        outs.append((vals.detach(), logDs.detach()))\n",
    "    \n",
    "    vals = torch.cat([x[0] for x in outs])\n",
    "    logDs = torch.cat([x[1] for x in outs])\n",
    "    \n",
    "    probs = smoothed_circle_density(vals.reshape(-1,2)).reshape(xsize, ysize)\n",
    "    return (probs*logDs.reshape(xsize, ysize)).cpu().numpy().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9158318c-a0fa-420c-a415-d7e8ae1e78a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bf6b8e113442c5a7a639d58d559e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = heatmap(lambda x: (x,torch.ones([x.shape[0],1], device=device)))\n",
    "%matplotlib widget\n",
    "sns.heatmap(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "39f24056-814a-4814-b003-8c5533c413a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 512\n",
    "def fc_constr(c_in, c_out):\n",
    "    \"\"\"Plug-n-play fully connected net for INNs\"\"\"\n",
    "    layers = [nn.Linear(c_in, width), nn.ReLU()]\n",
    "    for _ in range(5):\n",
    "        layers.append(nn.Linear(width,  width))\n",
    "        layers.append(nn.ReLU())\n",
    "    layers.append(nn.Linear(width,  c_out))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b073e8f-f61d-4897-9846-9f62188fefa4",
   "metadata": {},
   "source": [
    "## KL-divergence for samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e0abacf8-1e4c-4c9c-a950-84604280c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KL_divergence(s1, s2, k=1):\n",
    "    n, m = len(s1), len(s2)\n",
    "    D = torch.tensor(m / (n - 1), dtype=torch.float, device=device).log()\n",
    "    d = torch.tensor(s1.shape[1], device=device).float()\n",
    "\n",
    "    for pt in s1:\n",
    "        # Estimate densities using the kth nearest neighbor. Idea from:\n",
    "        # Qing Wang, Sanjeev R. Kulkarni, and Sergio Verdú. \"Divergence estimation for multidimensional densities via k-nearest-neighbor distances.\" Information Theory, IEEE Transactions on 55.5 (2009): 2392-2405.\n",
    "        norms = (s2-pt).norm(dim=1).reshape(-1)\n",
    "        nu = norms[~(norms == 0)].kthvalue(k=k)[0]\n",
    "\n",
    "        norms = (s1-pt).norm(dim=1).reshape(-1)\n",
    "        rho = norms[~(norms == 0)].kthvalue(k=k)[0]\n",
    "\n",
    "        D += (d/n)*(nu/rho).log()\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c53d649-b74a-47ff-b8e7-a9d1cc69511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [Ff.InputNode(2, name='Input')]\n",
    "\n",
    "for i in range(5):\n",
    "    layers.append(Ff.Node(\n",
    "        [layers[-1].out0],\n",
    "        Fm.RNVPCouplingBlock,#Fm.GINCouplingBlock,\n",
    "        {'subnet_constructor':fc_constr},\n",
    "        name=f'GIN {i}')\n",
    "    )\n",
    "    layers.append(Ff.Node([layers[-1].out0], Fm.PermuteRandom, {}))\n",
    "\n",
    "layers.append(Ff.OutputNode([layers[-1].out0], name='Output'))\n",
    "\n",
    "model = Ff.ReversibleGraphNet(layers, verbose=False)\n",
    "_ = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55561e99-9ee3-4e32-b8ba-cedf2336a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 21.70546531677246\n",
      "Epoch 1 loss: 21.489843368530273\n",
      "Epoch 2 loss: 20.755199432373047\n",
      "Epoch 3 loss: 20.114192962646484\n",
      "Epoch 4 loss: 19.569581985473633\n",
      "Epoch 5 loss: 18.985801696777344\n",
      "Epoch 6 loss: 18.285877227783203\n",
      "Epoch 7 loss: 17.637351989746094\n",
      "Epoch 8 loss: 16.93558120727539\n",
      "Epoch 9 loss: 16.593053817749023\n",
      "Epoch 10 loss: 16.39727020263672\n",
      "Epoch 11 loss: 15.725844383239746\n",
      "Epoch 12 loss: 14.936430931091309\n",
      "Epoch 13 loss: 14.200597763061523\n",
      "Epoch 14 loss: 13.37991714477539\n",
      "Epoch 15 loss: 12.699832916259766\n",
      "Epoch 16 loss: 10.304031372070312\n",
      "Epoch 17 loss: 9.436872482299805\n",
      "Epoch 18 loss: 9.209270477294922\n",
      "Epoch 19 loss: 8.556109428405762\n",
      "Epoch 20 loss: 7.46096134185791\n",
      "Epoch 21 loss: 8.385290145874023\n",
      "Epoch 22 loss: 8.822319030761719\n",
      "Epoch 23 loss: 9.59246826171875\n",
      "Epoch 24 loss: 10.271574020385742\n",
      "Epoch 25 loss: 10.336284637451172\n",
      "Epoch 26 loss: 9.386771202087402\n",
      "Epoch 27 loss: 10.301192283630371\n",
      "Epoch 28 loss: 10.640898704528809\n",
      "Epoch 29 loss: 9.044719696044922\n",
      "Epoch 30 loss: 10.160438537597656\n",
      "Epoch 31 loss: 10.016050338745117\n",
      "Epoch 32 loss: 10.674834251403809\n",
      "Epoch 33 loss: 11.899229049682617\n",
      "Epoch 34 loss: 11.638339042663574\n",
      "Epoch 35 loss: 11.632144927978516\n",
      "Epoch 36 loss: 11.05505084991455\n",
      "Epoch 37 loss: 10.687644958496094\n",
      "Epoch 38 loss: 11.651060104370117\n",
      "Epoch 39 loss: 10.727484703063965\n",
      "Epoch 40 loss: 10.363687515258789\n",
      "Epoch 41 loss: 10.405908584594727\n",
      "Epoch 42 loss: 9.01904010772705\n",
      "Epoch 43 loss: 9.252808570861816\n",
      "Epoch 44 loss: 7.532360076904297\n",
      "Epoch 45 loss: 7.712950706481934\n",
      "Epoch 46 loss: 7.441812515258789\n",
      "Epoch 47 loss: 6.953514099121094\n",
      "Epoch 48 loss: 6.870650291442871\n",
      "Epoch 49 loss: 7.5362629890441895\n",
      "Epoch 50 loss: 6.560831069946289\n",
      "Epoch 51 loss: 7.5803375244140625\n",
      "Epoch 52 loss: 7.224762916564941\n",
      "Epoch 53 loss: 7.483303070068359\n",
      "Epoch 54 loss: 6.877044200897217\n",
      "Epoch 55 loss: 7.940641403198242\n",
      "Epoch 56 loss: 7.102347373962402\n",
      "Epoch 57 loss: 7.897150039672852\n",
      "Epoch 58 loss: 7.612393856048584\n",
      "Epoch 59 loss: 6.851343154907227\n",
      "Epoch 60 loss: 6.057537078857422\n",
      "Epoch 61 loss: 6.7079057693481445\n",
      "Epoch 62 loss: 6.445291996002197\n",
      "Epoch 63 loss: 6.1229448318481445\n",
      "Epoch 64 loss: 6.3213348388671875\n",
      "Epoch 65 loss: 6.171342849731445\n",
      "Epoch 66 loss: 5.8625359535217285\n",
      "Epoch 67 loss: 6.387659072875977\n",
      "Epoch 68 loss: 6.543037414550781\n",
      "Epoch 69 loss: 5.606742858886719\n",
      "Epoch 70 loss: 5.630877494812012\n",
      "Epoch 71 loss: 5.491395950317383\n",
      "Epoch 72 loss: 5.124093055725098\n",
      "Epoch 73 loss: 5.193609237670898\n",
      "Epoch 74 loss: 5.105953216552734\n",
      "Epoch 75 loss: 4.710737228393555\n",
      "Epoch 76 loss: 5.353837013244629\n",
      "Epoch 77 loss: 5.204331874847412\n",
      "Epoch 78 loss: 4.704844951629639\n",
      "Epoch 79 loss: 4.998649597167969\n",
      "Epoch 80 loss: 5.394892692565918\n",
      "Epoch 81 loss: 5.1414384841918945\n",
      "Epoch 82 loss: 4.969100475311279\n",
      "Epoch 83 loss: 5.654604434967041\n",
      "Epoch 84 loss: 6.035650253295898\n",
      "Epoch 85 loss: 6.928434371948242\n",
      "Epoch 86 loss: 7.8711981773376465\n",
      "Epoch 87 loss: 8.074365615844727\n",
      "Epoch 88 loss: 7.561141014099121\n",
      "Epoch 89 loss: 8.415403366088867\n",
      "Epoch 90 loss: 8.265312194824219\n",
      "Epoch 91 loss: 9.023282051086426\n",
      "Epoch 92 loss: 9.470817565917969\n",
      "Epoch 93 loss: 11.070782661437988\n",
      "Epoch 94 loss: 11.186800003051758\n",
      "Epoch 95 loss: 11.149320602416992\n",
      "Epoch 96 loss: 11.067567825317383\n",
      "Epoch 97 loss: 10.573952674865723\n",
      "Epoch 98 loss: 9.737747192382812\n",
      "Epoch 99 loss: 10.052961349487305\n",
      "Epoch 100 loss: 10.394859313964844\n",
      "Epoch 101 loss: 9.608601570129395\n",
      "Epoch 102 loss: 9.460090637207031\n",
      "Epoch 103 loss: 9.256200790405273\n",
      "Epoch 104 loss: 9.161611557006836\n",
      "Epoch 105 loss: 9.64053726196289\n",
      "Epoch 106 loss: 10.230667114257812\n",
      "Epoch 107 loss: 8.613092422485352\n",
      "Epoch 108 loss: 9.97705078125\n",
      "Epoch 109 loss: 10.132766723632812\n",
      "Epoch 110 loss: 9.733365058898926\n",
      "Epoch 111 loss: 9.514893531799316\n",
      "Epoch 112 loss: 11.041183471679688\n",
      "Epoch 113 loss: 10.014921188354492\n",
      "Epoch 114 loss: 10.361011505126953\n",
      "Epoch 115 loss: 11.943663597106934\n",
      "Epoch 116 loss: 10.444262504577637\n",
      "Epoch 117 loss: 11.774839401245117\n",
      "Epoch 118 loss: 10.89268684387207\n",
      "Epoch 119 loss: 10.500192642211914\n",
      "Epoch 120 loss: 10.789619445800781\n",
      "Epoch 121 loss: 10.11982250213623\n",
      "Epoch 122 loss: 9.950984001159668\n",
      "Epoch 123 loss: 9.950300216674805\n",
      "Epoch 124 loss: 10.44956111907959\n",
      "Epoch 125 loss: 9.376096725463867\n",
      "Epoch 126 loss: 8.428618431091309\n",
      "Epoch 127 loss: 8.247079849243164\n",
      "Epoch 128 loss: 8.137998580932617\n",
      "Epoch 129 loss: 7.151932239532471\n",
      "Epoch 130 loss: 5.901145935058594\n",
      "Epoch 131 loss: 6.695858955383301\n",
      "Epoch 132 loss: 5.60261869430542\n",
      "Epoch 133 loss: 5.401363372802734\n",
      "Epoch 134 loss: 5.103159427642822\n",
      "Epoch 135 loss: 5.264828205108643\n",
      "Epoch 136 loss: 4.458415985107422\n",
      "Epoch 137 loss: 5.451958656311035\n",
      "Epoch 138 loss: 4.760383129119873\n",
      "Epoch 139 loss: 4.5937395095825195\n",
      "Epoch 140 loss: 4.443542003631592\n",
      "Epoch 141 loss: 4.524634838104248\n",
      "Epoch 142 loss: 3.792083740234375\n",
      "Epoch 143 loss: 4.461433410644531\n",
      "Epoch 144 loss: 4.31028938293457\n",
      "Epoch 145 loss: 4.778822422027588\n",
      "Epoch 146 loss: 3.7964768409729004\n",
      "Epoch 147 loss: 4.10849666595459\n",
      "Epoch 148 loss: 4.1075663566589355\n",
      "Epoch 149 loss: 4.230592727661133\n",
      "Epoch 150 loss: 4.217992782592773\n",
      "Epoch 151 loss: 4.260097026824951\n",
      "Epoch 152 loss: 3.936673402786255\n",
      "Epoch 153 loss: 3.716521978378296\n",
      "Epoch 154 loss: 3.6303069591522217\n",
      "Epoch 155 loss: 3.9623889923095703\n",
      "Epoch 156 loss: 3.5909175872802734\n",
      "Epoch 157 loss: 4.58311128616333\n",
      "Epoch 158 loss: 4.136042594909668\n",
      "Epoch 159 loss: 5.237288475036621\n",
      "Epoch 160 loss: 4.810332298278809\n",
      "Epoch 161 loss: 4.591586112976074\n",
      "Epoch 162 loss: 4.1478071212768555\n",
      "Epoch 163 loss: 3.5325000286102295\n",
      "Epoch 164 loss: 3.7448155879974365\n",
      "Epoch 165 loss: 4.482235908508301\n",
      "Epoch 166 loss: 3.9292874336242676\n",
      "Epoch 167 loss: 3.8511009216308594\n",
      "Epoch 168 loss: 3.9154224395751953\n",
      "Epoch 169 loss: 3.8661742210388184\n",
      "Epoch 170 loss: 4.062573432922363\n",
      "Epoch 171 loss: 4.2312750816345215\n",
      "Epoch 172 loss: 4.198154449462891\n",
      "Epoch 173 loss: 4.060675144195557\n",
      "Epoch 174 loss: 3.816286087036133\n",
      "Epoch 175 loss: 4.013850212097168\n",
      "Epoch 176 loss: 4.173610687255859\n",
      "Epoch 177 loss: 4.067584991455078\n",
      "Epoch 178 loss: 4.628597736358643\n",
      "Epoch 179 loss: 4.679609298706055\n",
      "Epoch 180 loss: 4.435761451721191\n",
      "Epoch 181 loss: 4.306044101715088\n",
      "Epoch 182 loss: 4.428388595581055\n",
      "Epoch 183 loss: 5.512451171875\n",
      "Epoch 184 loss: 4.885037899017334\n",
      "Epoch 185 loss: 4.752348899841309\n",
      "Epoch 186 loss: 4.334585189819336\n",
      "Epoch 187 loss: 5.001888275146484\n",
      "Epoch 188 loss: 5.231137752532959\n",
      "Epoch 189 loss: 5.056121826171875\n",
      "Epoch 190 loss: 5.291045188903809\n",
      "Epoch 191 loss: 4.569843292236328\n",
      "Epoch 192 loss: 4.793534278869629\n",
      "Epoch 193 loss: 4.936083793640137\n",
      "Epoch 194 loss: 4.621203422546387\n",
      "Epoch 195 loss: 4.517084121704102\n",
      "Epoch 196 loss: 4.45908260345459\n",
      "Epoch 197 loss: 3.280609130859375\n",
      "Epoch 198 loss: 3.3860230445861816\n",
      "Epoch 199 loss: 3.6061391830444336\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.ioff()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=1e-4,\n",
    "    weight_decay=0\n",
    ")\n",
    "\n",
    "for epoch in range(200):\n",
    "    losses = []\n",
    "    model.zero_grad()\n",
    "\n",
    "    angles = 2*np.pi*torch.rand([1000,1], device=device)\n",
    "    samples = torch.cat([angles.cos(),angles.sin()], dim=1)\n",
    "\n",
    "    z_hat, _ = model(samples, rev=True)\n",
    "    \n",
    "    true = true_sample(1000).to(device)\n",
    "    \n",
    "    loss = 0\n",
    "    loss += KL_divergence(z_hat, true, k=1)\n",
    "    loss += KL_divergence(true, z_hat, k=1)\n",
    "    losses.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Epoch {epoch} loss: {sum(losses)/len(losses)}', end='\\r')\n",
    "    \n",
    "    plt.close()\n",
    "    arr = heatmap(model)\n",
    "    _ = sns.heatmap(arr)\n",
    "    plt.title(f'Epoch {epoch} density')\n",
    "    plt.savefig(f'gaussian/circle_flow/epoch-{epoch}.png')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9ea8a-b9d0-4f81-bee0-e5ff6b28086d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6208bb-97a3-4c9e-8058-b1c998596bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "43dd500e-783a-487a-9461-d80cf92606fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for pts, _ in loader:\n",
    "    pts = torch.stack(pts)\n",
    "    yhat, _ = model(pts)\n",
    "    outs.append(yhat.detach().cpu())\n",
    "outs = torch.cat(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "676afff9-038f-4624-b9bf-1591dc0cd71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 4])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2ee895f7-0b82-47bb-ad64-e9687666ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = outs.std(0, unbiased=True)\n",
    "means = outs.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cbab259d-46ae-4b02-acf1-ea94a7355fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0778,  0.1543, -0.1162, -0.0541]) tensor([1.0456e+00, 1.1054e+00, 5.9175e-05, 7.0614e-05])\n"
     ]
    }
   ],
   "source": [
    "print(means,stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1e331155-01a1-4028-ae1f-090304957bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = stds*torch.randn(10000, 4) + means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bb4e603a-b4d8-40ca-9b67-fadde7190daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader2 = make_dataloader(samples, torch.zeros_like(circle), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6279bad1-e423-40b3-a317-9c1007c710b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "for pts, _ in loader2:\n",
    "    pts = torch.stack(pts)\n",
    "    yhat, _ = model(pts, rev=True)\n",
    "    outs.append(yhat.detach().cpu())\n",
    "outs = torch.cat(outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "056d54bc-45e0-496c-8a96-4acb8c2a3a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "057b7b1f551841adb7d3c2420abda232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Generated data from Gaussian priors (n=10,000)')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "\n",
    "plt.scatter(outs[:,0], outs[:,1], s=5)\n",
    "plt.xlim([-1.5,1.5])\n",
    "plt.ylim([-1.5,1.5])\n",
    "plt.title('Generated data from Gaussian priors (n=10,000)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6999c162-0f57-482d-bf02-d285e720e930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611082b912ae4e23883ae5d3190a0092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distances from zero')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import seaborn as sns\n",
    "sns.histplot(outs[:,:2].norm(dim=1))\n",
    "plt.title('Distances from zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04cdbf-379e-425b-9862-fd4c7e9ca29d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
